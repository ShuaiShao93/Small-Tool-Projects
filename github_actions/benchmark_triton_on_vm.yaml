# Builds an image from branch, run it on a gce instance, run benchmark against it, and commit results to the branch

name: Latency Benchmark

on:
  workflow_dispatch:
    inputs:
      model-name:
        description: "Which model to benchmark"
        required: true
        default: "emotions"

env:
  GCP_PROJECT_ID: 12345
  ZONE: "us-central1-c"
  INSTANCE_NAME: "wizard-benchmark-${GITHUB_SHA::8}"

jobs:
  docker-build-and-push:
    runs-on: ubuntu-latest
    outputs:
      final_tag: ${{ steps.preprocess_tag.outputs.processed_tag }}
    permissions:
      contents: "read"
      id-token: "write"
    if: ${{ github.ref != 'refs/heads/main' }}

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: false
          docker-images: true
          swap-storage: true

      - name: Checkout
        uses: actions/checkout@v4

      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Login to GCR
        uses: docker/login-action@v3
        with:
          registry: gcr.io
          username: oauth2accesstoken
          password: ${{ steps.gcp_auth.outputs.access_token }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Pre-process branch for tag
        id: preprocess_tag
        run: |
          PROCESSED_TAG=$(echo '${{ github.ref }}' | sed 's/\//-/g')
          echo "PROCESSED_TAG=$PROCESSED_TAG" >> $GITHUB_ENV
          echo "::set-output name=processed_tag::$PROCESSED_TAG"

      - name: Docker Build and Push
        uses: docker/build-push-action@v5
        with:
          cache-from: type=gha
          cache-to: type=gha,mode=max
          context: .
          push: true
          build-args: |
            EXAMPLE_ARG=1234
          tags: gcr.io/org/ml-server:${{ env.PROCESSED_TAG }}

  benchmark:
    # Pin the version because we use a fixed version for cuda-keyring
    runs-on: ubuntu-22.04
    permissions:
      contents: "write"
      id-token: "write"
    needs: docker-build-and-push
    if: ${{ ! failure() && ! cancelled() }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Extract image tag
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            USE_TAG="main"
          else
            USE_TAG="${{ needs.docker-build-and-push.outputs.final_tag }}"
          fi
          echo "Using tag: $USE_TAG"
          echo "USE_TAG=$USE_TAG" >> $GITHUB_ENV

      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Create Preemptible VM
        run: |
          gcloud compute instances create ${{ env.INSTANCE_NAME }} \
              --service-account="github-actions@org.iam.gserviceaccount.com" \
              --zone="${{ env.ZONE }}" \
              --machine-type="e2-standard-2" \
              --preemptible \
              --boot-disk-size=40 \
              --tags=triton-benchmark

          gcloud compute firewall-rules create allow-triton-server --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=tcp:8000 --source-ranges=0.0.0.0/0 --target-tags=triton-benchmark

          echo "VM_PUBLIC_IP=$(gcloud compute instances describe ${{ env.INSTANCE_NAME }} \
            --zone="${{ env.ZONE }}" \
            --format='get(networkInterfaces[0].accessConfigs[0].natIP)')" >> $GITHUB_ENV

      - name: Install docker
        run: |
          gcloud compute ssh ${{ env.INSTANCE_NAME }} --zone=${{ env.ZONE }} --command='
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg &&
            sudo apt-get update &&
            sudo apt-get install -y google-cloud-cli docker.io &&
            gcloud auth configure-docker --quiet &&
            sudo usermod -aG docker $USER &&
            newgrp docker
          '

      - name: Pull Image and Run Triton Server
        run: |
          gcloud compute ssh ${{ env.INSTANCE_NAME }} --zone=${{ env.ZONE }} --command='
            docker pull gcr.io/org/ml-server:${{ env.USE_TAG }} &&
            docker run --shm-size=256m --rm -d -p 8000:8000 -e ENV=${{ secrets.SOME_TOKEN }} gcr.io/org/ml-server:${{ env.USE_TAG }}
          '

      - name: Install perf_analyzer
        run: |
          set -e

          # Perf analyzer depends on libcudart, even if there is no GPU on the machine
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          sudo apt update
          sudo apt install -y python3-pip libb64-dev cuda-cudart-12-4
          sudo pip3 install tritonclient[http]

      - name: Wait for Service to be Ready
        run: |
          echo "Waiting for service at ${{ env.VM_PUBLIC_IP }}:8000/v2/health/ready to be ready..."
          until curl --output /dev/null --silent --fail "http://${{ env.VM_PUBLIC_IP }}:8000/v2/health/ready"; do
            sleep 5
          done
          echo "Service is ready."

      - name: Run Benchmark
        run: |
          set -e
          echo "Running benchmark for ${{ github.event.inputs.model-name }}"
          for string_length in 100 500; do
            command="perf_analyzer \
              -m ${{ github.event.inputs.model-name }} \
              -u ${{ env.VM_PUBLIC_IP }}:8000 \
              --input-data=\"random\" \
              --measurement-interval=60000 \
              --stability-percentage=20 \
              -b 8 \
              --string-length=\"$string_length\" \
            "
            echo "$command" | tee -a perf.txt
            echo -e "\n\n" | tee -a perf.txt
            eval $command 2>&1 | tee -a perf.txt
            echo -e "\n\n" | tee -a perf.txt
          done

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-results
          path: perf.txt

      - name: Copy Benchmark Results
        if: ${{ github.ref != 'refs/heads/main' }}
        run: |
          MODEL_NAME="${{ github.event.inputs.model-name }}"
          # Copy perf.txt to the specified directory, creating it if necessary
          mkdir -p models/$MODEL_NAME
          cp perf.txt models/$MODEL_NAME/

      - name: Commit Performance Results
        if: ${{ github.ref != 'refs/heads/main' }}
        uses: EndBug/add-and-commit@v9
        with:
          message: "Add performance results for ${{ github.event.inputs.model-name }}"
          add: "models/${{ github.event.inputs.model-name }}/perf.txt"
          committer_name: GitHub Actions
          committer_email: actions@github.com
          push: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Cleans up VM in a separate job to ensure it runs even if the benchmark fails.
  cleanup_vm:
    runs-on: ubuntu-latest
    permissions:
      contents: "read"
      id-token: "write"
    needs: benchmark
    if: always()

    steps:
      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Delete Preemptible VM
        run: |
          gcloud compute instances delete ${{ env.INSTANCE_NAME }} --zone="${{ env.ZONE }}" --quiet
