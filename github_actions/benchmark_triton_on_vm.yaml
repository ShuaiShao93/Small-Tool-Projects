# Builds an image from branch, run it on a gce instance, run benchmark against it, and commit results to the branch

name: Latency Benchmark

on:
  workflow_dispatch:
    inputs:
      model-name:
        description: "Which model to benchmark"
        required: true
        default: "emotions"

env:
  GCP_PROJECT_ID: 12345
  ZONE: "us-central1-c"
  INSTANCE_NAME: "wizard-benchmark-${GITHUB_RUN_NUMBER}"
  # Config file is like:
  # ModelA:
  #   measurement_request_count: 30
  #   stability_percentage: 20
  #   batch_size: 8
  #   string_length: [100, 500]
  # ModelB:
  #   ...
  BENCHMARK_CONFIG: "latency_benchmark/latency_benchmark_config.yaml"

jobs:
  docker-build-and-push:
    runs-on: ubuntu-latest
    outputs:
      final_tag: ${{ steps.preprocess_tag.outputs.processed_tag }}
    permissions:
      contents: "read"
      id-token: "write"
    if: ${{ github.ref != 'refs/heads/main' }}

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: false
          docker-images: true
          swap-storage: true

      - name: Checkout
        uses: actions/checkout@v4

      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Login to GCR
        uses: docker/login-action@v3
        with:
          registry: gcr.io
          username: oauth2accesstoken
          password: ${{ steps.gcp_auth.outputs.access_token }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Pre-process branch for tag
        id: preprocess_tag
        run: |
          PROCESSED_TAG=$(echo '${{ github.ref }}' | sed 's/\//-/g')
          echo "PROCESSED_TAG=$PROCESSED_TAG" >> $GITHUB_ENV
          echo "::set-output name=processed_tag::$PROCESSED_TAG"

      - name: Docker Build and Push
        uses: docker/build-push-action@v5
        with:
          cache-from: type=gha
          cache-to: type=gha,mode=max
          context: .
          push: true
          build-args: |
            EXAMPLE_ARG=1234
          tags: gcr.io/org/ml-server:${{ env.PROCESSED_TAG }}

  benchmark:
    # Pin the version because we use a fixed version for cuda-keyring
    runs-on: ubuntu-22.04
    permissions:
      contents: "write"
      id-token: "write"
    needs: docker-build-and-push
    if: ${{ ! failure() && ! cancelled() }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify Model and Configuration
        run: |
          set -e
          # install yq for yaml parsing
          sudo snap install yq
          MODEL_NAME="${{ github.event.inputs.model-name }}"
          MODEL_DIR="models/$MODEL_NAME"
          if [ ! -d "$MODEL_DIR" ]; then
            echo "Directory $MODEL_DIR does not exist."
            exit 1
          fi
          MODEL_CONFIG=$(yq e ".${MODEL_NAME}" "$BENCHMARK_CONFIG")
          if [ "$MODEL_CONFIG" = "null" ]; then
            echo "${MODEL_NAME} does not exist in $BENCHMARK_CONFIG."
            exit 1
          fi
          echo "Verification successful: ${MODEL_NAME} exists both as a directory and in the configuration file."

      - name: Extract image tag
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            USE_TAG="main"
          else
            USE_TAG="${{ needs.docker-build-and-push.outputs.final_tag }}"
          fi
          echo "Using tag: $USE_TAG"
          echo "USE_TAG=$USE_TAG" >> $GITHUB_ENV

      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Create Preemptible VM
        run: |
          gcloud compute instances create ${{ env.INSTANCE_NAME }} \
              --service-account="github-actions@org.iam.gserviceaccount.com" \
              --zone="${{ env.ZONE }}" \
              --machine-type="n1-standard-8" \
              --accelerator="type=nvidia-tesla-t4,count=1" \
              --metadata="install-nvidia-driver=True" \
              --maintenance-policy TERMINATE --restart-on-failure \
              --image=${CUSTOM_IMAGE_WITH_CUDA_INSTALLED} \
              --preemptible \
              --boot-disk-size=200 \
              --tags=triton-benchmark

          gcloud compute firewall-rules create allow-triton-server --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=tcp:8000 --source-ranges=0.0.0.0/0 --target-tags=triton-benchmark

          echo "VM_PUBLIC_IP=$(gcloud compute instances describe ${{ env.INSTANCE_NAME }} \
            --zone="${{ env.ZONE }}" \
            --format='get(networkInterfaces[0].accessConfigs[0].natIP)')" >> $GITHUB_ENV

      - name: Install docker
        run: |
          gcloud compute ssh ${{ env.INSTANCE_NAME }} --zone=${{ env.ZONE }} --command='
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg &&
            sudo apt-get update &&
            sudo apt-get install -y google-cloud-cli docker.io &&
            gcloud auth configure-docker --quiet &&
            sudo usermod -aG docker $USER &&
            newgrp docker
          '

      - name: Pull Image and Run Triton Server
        run: |
          gcloud compute ssh ${{ env.INSTANCE_NAME }} --zone=${{ env.ZONE }} --command='
            docker pull gcr.io/org/ml-server:${{ env.USE_TAG }} &&
            docker run --cpus="1" --rm -d -p 8000:8000 -e ENV=${{ secrets.SOME_TOKEN }} gcr.io/org/ml-server:${{ env.USE_TAG }}
          '

      - name: Install perf_analyzer
        run: |
          set -e

          # Perf analyzer depends on libcudart, even if there is no GPU on the machine
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          sudo apt update
          sudo apt install -y python3-pip libb64-dev cuda-cudart-12-4
          sudo pip3 install tritonclient[http]

      - name: Wait for Service to be Ready
        run: |
          echo "Waiting for service at ${{ env.VM_PUBLIC_IP }}:8000/v2/health/ready to be ready..."
          until curl --output /dev/null --silent --fail "http://${{ env.VM_PUBLIC_IP }}:8000/v2/health/ready"; do
            sleep 5
          done
          echo "Service is ready."

      - name: Run Benchmark
        run: |
          set -e
          echo "Loading model ${{ github.event.inputs.model-name }}"

          START_TIME=$(date +%s)
          curl -X POST "http://${{ env.VM_PUBLIC_IP }}:8000/v2/repository/models/${{ github.event.inputs.model-name }}/load" -d "{}"
          END_TIME=$(date +%s)
          LOAD_DURATION=$((END_TIME - START_TIME))
          echo "Model ${{ github.event.inputs.model-name }} loaded in ${LOAD_DURATION} seconds." | tee -a perf.txt
          echo -e "\n" | tee -a perf.txt

          echo "Running benchmark for ${{ github.event.inputs.model-name }}"

          MEASUREMENT_REQUEST_COUNT=$(yq e ".${{ github.event.inputs.model-name }}.measurement_request_count" $BENCHMARK_CONFIG)
          BATCH_SIZE=$(yq e ".${{ github.event.inputs.model-name }}.batch_size" $BENCHMARK_CONFIG)
          STRING_LENGTHS=$(yq e ".${{ github.event.inputs.model-name }}.string_length[]" $BENCHMARK_CONFIG)
          STABILITY_PERCENTAGE=$(yq e ".${{ github.event.inputs.model-name }}.stability_percentage" $BENCHMARK_CONFIG)
          SHAPE=$(yq e ".${{ github.event.inputs.model-name }}.shape" $BENCHMARK_CONFIG)
          for STRING_LENGTH in $STRING_LENGTHS; do
            command="perf_analyzer \
              -m ${{ github.event.inputs.model-name }} \
              -u ${{ env.VM_PUBLIC_IP }}:8000 \
              --measurement-mode=\"count_windows\" \
              --input-data=\"random\" \
              --measurement-request-count=\"$MEASUREMENT_REQUEST_COUNT\" \
              -b \"$BATCH_SIZE\" \
              --string-length=\"$STRING_LENGTH\" \
            "
            if [ "$STABILITY_PERCENTAGE" != "null" ]; then
              command="$command --stability-percentage=\"$STABILITY_PERCENTAGE\""
            fi
            if [ "$SHAPE" != "null" ]; then
              command="$command --shape=\"$SHAPE\""
            fi
            echo "$command" | tee -a perf.txt
            echo -e "\n" | tee -a perf.txt
            eval $command 2>&1 | tee -a perf.txt
            echo -e "\n" | tee -a perf.txt
          done

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v2
        with:
          name: benchmark-results
          path: perf.txt

      - name: Import SSH key for signing
        uses: webfactory/ssh-agent@v0.9.0
        if: ${{ github.event.inputs.auto-commit == 'true' && github.ref != 'refs/heads/main' }}
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Configure git
        if: ${{ github.event.inputs.auto-commit == 'true' && github.ref != 'refs/heads/main' }}
        run: |
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > ssh_public_key.pub
          git config --global gpg.format ssh
          git config --global user.signingkey ssh_public_key.pub

      - name: Copy Benchmark Results
        if: ${{ github.ref != 'refs/heads/main' }}
        run: |
          MODEL_NAME="${{ github.event.inputs.model-name }}"
          # Copy perf.txt to the specified directory, creating it if necessary
          mkdir -p models/$MODEL_NAME
          cp perf.txt models/$MODEL_NAME/

      - name: Commit Performance Results
        if: ${{ github.ref != 'refs/heads/main' }}
        uses: EndBug/add-and-commit@v9
        with:
          message: "Add performance results for ${{ github.event.inputs.model-name }}"
          add: "models/${{ github.event.inputs.model-name }}/perf.txt"
          committer_name: GitHub Actions
          committer_email: actions@github.com
          pull: --rebase --autostash
          push: true
          commit: -S
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Cleans up VM in a separate job to ensure it runs even if the benchmark fails.
  cleanup_vm:
    runs-on: ubuntu-latest
    permissions:
      contents: "read"
      id-token: "write"
    needs: benchmark
    if: always()

    steps:
      - id: gcp_auth
        name: GCR Auth
        uses: "google-github-actions/auth@v2"
        with:
          token_format: access_token
          workload_identity_provider: "projects/${{ env.GCP_PROJECT_ID }}/locations/global/workloadIdentityPools/github/providers/github"
          service_account: "github-actions@org.iam.gserviceaccount.com"

      - name: Delete Preemptible VM
        run: |
          gcloud compute instances delete ${{ env.INSTANCE_NAME }} --zone="${{ env.ZONE }}" --quiet
